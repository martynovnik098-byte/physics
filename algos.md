Хорошо. Я отвечаю на **все** вопросы из твоего первого списка по порядку.

Там, где материал есть в твоих лекциях — я опираюсь на них. Там, где нет (деревья, хеш-таблицы) — я даю стандартную академическую базу, которую требуют в курсе Алгоритмов и структур данных (АиСД).

---

### Основные вопросы

#### 1. Как оценить эффективность алгоритма? Что такое асимптотическая сложность алгоритма?
*   **Эффективность** оценивается по двум ресурсам:
    1.  **Время:** количество элементарных операций процессора.
    2.  **Память:** объем дополнительной оперативной памяти (RAM).
*   **Асимптотическая сложность ($O$-нотация):** Это математическая оценка того, как растет время работы (или память) алгоритма при увеличении объема входных данных ($n$) до бесконечности.
    *   Мы отбрасываем конкретные секунды и коэффициенты, оставляя только класс функции (линейная, квадратичная и т.д.), чтобы сравнивать алгоритмы абстрактно, без привязки к "железу".

#### 2. Выразите функцию в тета-обозначениях.
*Функция:* $f(n) = \frac{n^3}{1000} - 100n^2 - 100n + 3$.
*   **Правило:** В $\Theta$-нотации (Тета) мы оставляем только самое быстрорастущее слагаемое (старшую степень) и отбрасываем все константы.
*   **Ответ:** $\Theta(n^3)$.
*   **Обоснование:** При $n \to \infty$ член $n^3$ будет доминировать над $n^2$ и $n$.

#### 3. Поиск элемента в массиве (Неотсортированный vs Отсортированный)
*   **Неотсортированный массив:**
    *   *Алгоритм:* **Линейный поиск**. Проходим циклом от начала до конца.
    *   *Сложность:* Лучший — $O(1)$ (нашли первым), Худший — $O(n)$ (прошли весь массив), Средний — $O(n)$.
*   **Отсортированный массив:**
    *   *Алгоритм:* **Бинарный (двоичный) поиск**. Сравниваем искомое с серединой. Если меньше — идем в левую половину, если больше — в правую.
    *   *Сложность:* $O(\log n)$.
    *   *Почему:* На каждом шаге мы отсекаем половину данных.

#### 4. Расположите функции по скорости их асимптотического роста (от быстрого к медленному)
1.  $O(1)$ — Константная (доступ по индексу).
2.  $O(\lg n)$ — Логарифмическая (бинарный поиск).
3.  $O(n)$ — Линейная (проход по массиву).
4.  $O(n \lg n)$ — Линейно-логарифмическая (эффективные сортировки: Merge Sort, Quick Sort в среднем).
5.  $O(n^2)$ — Квадратичная (вложенные циклы).

#### 5. Сравните динамический массив (vector) и связный список (list)
*   **Vector (Динамический массив):**
    *   Данные лежат в памяти непрерывным блоком.
    *   *Плюсы:* Доступ по индексу за $O(1)$. Отличная работа с кэшем процессора.
    *   *Минусы:* Вставка/удаление в середину — $O(n)$ (надо сдвигать элементы). Реаллокация памяти.
    *   *Применение:* Почти всегда по умолчанию.
*   **List (Связный список):**
    *   Каждый элемент хранит данные и указатель на следующий. Разбросаны по памяти.
    *   *Плюсы:* Вставка/удаление в любое место за $O(1)$ (если есть итератор на это место), так как не надо сдвигать данные, только перекинуть указатели.
    *   *Минусы:* Нет доступа по индексу ($O(n)$ чтобы дойти до $i$-го). Плохо для кэша.
    *   *Применение:* Когда много удалений/вставок в середину и не нужен произвольный доступ.

#### 6. Как построить словарь на хеш-таблице? Оценка сложности.
*   **Принцип:** Есть массив "корзин" (buckets). Специальная **хеш-функция** превращает ключ (например, строку "user") в число (индекс массива). Пара (ключ-значение) кладется в этот индекс.
*   **Коллизии:** Если у разных ключей совпал хеш, они попадают в одну корзину. Обычно там используется **связный список** (метод цепочек).
*   **Сложность (Вставка, Поиск, Удаление):**
    *   *Лучший/Средний:* $O(1)$. Мы сразу вычисляем индекс и берем данные.
    *   *Худший:* $O(n)$. Если хеш-функция плохая, все ключи попадут в одну корзину, и таблица превратится в длинный связный список.

#### 7. Как построить словарь на бинарном дереве поиска? Оценка сложности.
*   **Принцип:** Дерево, где у каждого узла есть ключ. Правило: **Все ключи в левом поддереве < Ключа узла < Все ключи в правом поддереве**.
*   **Операции:** Поиск похож на бинарный поиск в массиве (идем влево или вправо).
*   **Сложность:** Зависит от высоты дерева ($h$).
    *   *Лучший/Средний (сбалансированное дерево):* $O(\log n)$.
    *   *Худший (вырожденное дерево, "палка"):* $O(n)$ (если добавляли отсортированные данные в обычное дерево).
    *   *Примечание:* В C++ `std::map` использует Красно-черное дерево (самобалансирующееся), поэтому там гарантия $O(\log n)$ всегда.

#### 8. Как построить множество на бинарном дереве поиска?
*   Это то же самое, что и словарь (см. вопрос 7), только мы храним **только ключи**, без значений. Структура данных следит, чтобы ключи не повторялись и были отсортированы.
*   **Сложность:** $O(\log n)$ на вставку, поиск и удаление (в сбалансированном варианте).

#### 9. Как построить множество на хеш-таблице?
*   Это то же самое, что и словарь на хеш-таблице (см. вопрос 6), но храним только уникальные ключи. Порядок элементов хаотичный.
*   **Сложность:** В среднем $O(1)$, в худшем $O(n)$.

#### 10. Расскажите про стек и очередь.
*   **Стек (Stack):**
    *   Принцип: **LIFO** (Last In — First Out).
    *   Реализация: На векторе или списке.
    *   Операции: `push` (добавить вверх), `pop` (убрать сверху). Сложность $O(1)$.
*   **Очередь (Queue):**
    *   Принцип: **FIFO** (First In — First Out).
    *   Реализация: На списке или двусторонней очереди (deque).
    *   Операции: `push` (в хвост), `pop` (с головы). Сложность $O(1)$.

---

### Дополнительные вопросы

**1. Сложность оператора `[]` у `std::vector`? Почему?**
*   **$O(1)$**.
*   Вектор гарантирует непрерывность памяти. Адрес элемента вычисляется арифметически: `BaseAddress + Index * ElementSize`. Это одна процессорная инструкция.

**2. Что быстрее: пройтись по `std::vector` или по `std::list`? Почему?**
*   **Вектор быстрее.**
*   Причина в **локальности данных**. Вектор лежит в памяти подряд, процессор загружает данные в кэш целыми линиями (cache lines). Список разбросан по памяти, процессору приходится постоянно ждать подгрузки данных из RAM (Cache Misses).

**3. Что быстрее: вставить $10^7$ элементов в пустой вектор или в пустой список?**
*   **Вектор быстрее** (особенно с `reserve`).
*   Список на каждый элемент вызывает `new` (выделение памяти), что очень дорого. Вектор выделяет память большими кусками редко.

**4. Сложность вставки элемента в конец вектора.**
*   **Амортизированная $O(1)$**.
*   В большинстве случаев это просто запись в ячейку. Редко случается расширение массива (копирование), но в среднем операция очень дешевая.

**5. Сложность вставки элемента в начало вектора.**
*   **$O(n)$**.
*   Нужно сместить все $N$ элементов вправо на одну позицию, чтобы освободить место для нулевого элемента.

**6. Сложность вставки элемента в середину вектора.**
*   **$O(n)$**.
*   Нужно сместить половину элементов (хвост) вправо.

**7. Сложность удаления элемента из конца вектора.**
*   **$O(1)$**.
*   Просто уменьшается переменная размера (`size`), физически память не очищается мгновенно.

**8. Сложность удаления элемента из середины вектора.**
*   **$O(n)$**.
*   Нужно сместить хвост массива влево, чтобы закрыть образовавшуюся "дырку".

**9. Можно ли удалить произвольный элемент из вектора за O(1), если порядок не важен?**
*   **Да.**
*   **Трюк:** Берем элемент, который хотим удалить. Меняем его местами с **последним** элементом вектора (`swap`). Делаем `pop_back()` (удаляем последний).

**10. Задача: подсчет частоты чисел от 1 до 1000 при огромном N ($10^{10}$).**
*   **Решение:** Используем массив счетчиков (частотный массив) размером 1001.
*   Нам не нужно хранить сами числа ($10^{10}$ штук). Мы читаем число `x`, и делаем `counter[x]++`.
*   Память: $O(1)$ (так как размер массива константный = 1000). Время: $O(N)$.

**11. Для чего нужен метод `reserve()` у `std::vector`?**
*   Он заранее выделяет "сырую" память под указанное число элементов, меняя `capacity`.
*   Это предотвращает многократные **реаллокации** (выделение новой памяти + копирование старых данных) при добавлении элементов, что сильно ускоряет работу.

**12. Что такое `std::unordered_map`? Для чего у него есть метод `reserve()`?**
*   **`std::unordered_map`** — это реализация хеш-таблицы в C++.
*   **`reserve(n)`** здесь нужен, чтобы заранее создать достаточное количество "корзин" (buckets) для хранения $n$ элементов.
*   Это предотвращает **rehashing** (перестройку всей таблицы), который происходит, когда элементов становится слишком много для текущего количества корзин (когда превышен `load_factor`).
