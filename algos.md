Конечно. Давай разберем каждый вопрос «по косточкам», опираясь на твои лекции. Я буду выделять **термины** и объяснять их простым языком, чтобы ты понимал суть, а не просто заучивал.

---

### Основные вопросы

#### 1. Как оценить эффективность алгоритма? Что такое асимптотическая сложность?

**Ответ:**
Эффективность оценивают по двум ресурсам: **время** (сколько тактов процессора нужно) и **память** (сколько байт RAM нужно).
Но мы не меряем время в секундах, потому что компьютеры разные (на суперкомпьютере и телефоне время будет разным). Поэтому мы считаем **количество операций** в зависимости от входных данных ($n$).

**Пояснение за термины:**
*   **$n$ (размер входа):** Это количество данных, которые скармливают алгоритму. Например, размер массива.
*   **Асимптотическая сложность ($O$-нотация):** Это способ сказать, как быстро *растет* время работы, если $n$ станет очень большим (будет стремиться к бесконечности).
    *   *Пример:* Если алгоритм делает $2n$ операций, а другой $n^2$, то при $n=2$ они почти равны. Но при $n=1000$ первый сделает 2000 операций, а второй — 1 000 000. Асимптотика показывает именно этот характер роста, отбрасывая мелочи.

---

#### 2. Выразите функцию в тета-обозначениях: $f(n) = \frac{n^3}{1000} - 100n^2 - 100n + 3$

**Ответ:** $\Theta(n^3)$.

**Разбор:**
В лекциях сказано, что мы ищем функцию, которая **асимптотически эквивалентна** данной.
1.  Смотрим на слагаемые: $n^3$, $n^2$, $n$, и просто число 3.
2.  Кто здесь «главный»? При огромном $n$ (например, миллиард), $n^3$ будет настолько больше, чем $n^2$, что $n^2$ можно считать погрешностью. Мы оставляем только **старшую степень**.
3.  Коэффициенты (деление на 1000, умножение на 100) тоже отбрасываем. В асимптотике нам важна *форма* графика, а не масштаб.
4.  Итог: остается $n^3$.

**Термин:**
*   **$\Theta$ (Тета):** Это более строгая оценка, чем $O$. Она говорит: «Алгоритм работает *в точности* как эта функция (и не быстрее, и не медленнее) с точностью до константы».

---

#### 3. Поиск элемента: Неотсортированный vs Отсортированный массив

**А. Неотсортированный массив**
*   **Алгоритм:** **Линейный поиск** (Linear Search).
*   **Как работает:** Идем циклом от 0-го элемента до последнего. Сравниваем каждый с искомым.
*   **Оценка:**
    *   *Лучший случай:* Нашли сразу (он первый) — $O(1)$.
    *   *Худший случай:* Его нет или он в конце — $O(n)$.
    *   *Почему:* Приходится перебрать все $n$ элементов.

**Б. Отсортированный массив**
*   **Алгоритм:** **Бинарный поиск** (Binary Search). В лекции про сортировку вставками упоминается, что его можно использовать для ускорения.
*   **Как работает:** Тыкаем в середину. Если число больше искомого, отбрасываем правую половину. Если меньше — левую. Повторяем.
*   **Оценка:** $O(\log n)$.
*   **Почему:** С каждым шагом мы уменьшаем область поиска в 2 раза. Сколько раз можно поделить число $n$ на 2, пока не останется 1? Логарифм раз.

---

#### 4. Расположите функции по скорости роста (от быстрого к медленному)

1.  **$O(1)$** — **Константная**. Мгновенно. (Пример: доступ к массиву по индексу `a[5]`).
2.  **$O(\lg n)$** — **Логарифмическая**. Очень быстро. (Пример: бинарный поиск). *Термин:* $\lg$ — это логарифм по основанию 2.
3.  **$O(n)$** — **Линейная**. Пропорционально данным. (Пример: один проход циклом `for`).
4.  **$O(n \lg n)$** — **Линейно-логарифмическая**. Чуть медленнее линии. (Пример: хорошая сортировка, типа Merge Sort).
5.  **$O(n^2)$** — **Квадратичная**. Медленно. (Пример: вложенный цикл `for` внутри `for`, пузырьковая сортировка).

---

#### 5. Vector vs List (Динамический массив vs Связный список)

**std::vector (Динамический массив):**
*   **Суть:** Кусок памяти, где числа лежат плечом к плечу (0-й, 1-й, 2-й...).
*   **Плюсы:**
    *   Доступ `[i]` за $O(1)$ — мы просто знаем адрес.
    *   **Кэш-локальность:** Процессору удобно читать данные подряд.
*   **Минусы:**
    *   Тяжело вставлять в середину (надо сдвигать всех соседей).

**std::list (Связный список):**
*   **Суть:** Элементы разбросаны по памяти. Каждый элемент держит бумажку с адресом следующего.
*   **Плюсы:**
    *   Вставка в середину мгновенная ($O(1)$), если мы уже стоим там указателем. Не надо ничего сдвигать, просто переписать адреса.
*   **Минусы:**
    *   Нет доступа по индексу. Чтобы найти 5-й элемент, надо пройти через 1, 2, 3, 4.
    *   Плохо для процессора (скачем по памяти).

---

#### 6 - 9. Словари и Множества (Hash Tables & Trees)

*В твоих лекциях (1-4) этого материала нет. Но термины объясню кратко, на случай общих вопросов.*

*   **Хеш-таблица (Hash Table):** Это массив + функция, которая превращает ключ (например, слово "мама") в индекс (число 5). Кладем "мама" в 5-ю ячейку. Поиск мгновенный $O(1)$.
*   **Бинарное дерево поиска (BST):** Структура, где у каждого узла есть левый ребенок (меньше него) и правый (больше). Поиск работает как в бинарном поиске — спуск вниз. Сложность $O(\log n)$.

---

#### 10. Стек и Очередь

**Стек (Stack):**
*   **Принцип:** **LIFO** (Last In — First Out). Кто последним зашел, первым выйдет.
*   **Аналогия:** Обойма пистолета или стопка книг. Ты не можешь достать нижнюю книгу, не сняв верхние.
*   **Операции:** `push` (положить сверху), `pop` (снять сверху). Обе $O(1)$.

**Очередь (Queue):**
*   **Принцип:** **FIFO** (First In — First Out). Кто первым пришел, первым обслужен.
*   **Аналогия:** Очередь в кассу.
*   **Операции:** `push` (встать в хвост), `pop` (уйти с головы). Обе $O(1)$.

**Термин "Адаптер":**
В лекции сказано, что в C++ это не самостоятельные структуры, а «обертки». Внутри стека может лежать вектор или список. Стек просто запрещает тебе трогать элементы в середине, разрешая работу только с одним концом.

---

### Дополнительные вопросы (Разбор нюансов)

**1. Сложность `operator[]` у вектора?**
*   **Ответ:** $O(1)$.
*   **Почему:** Это чистая математика. Адрес = `База + Индекс * Размер_Элемента`. Процессор считает это за одно действие. Ему не нужно бегать по массиву.

**2. Что быстрее пройти: вектор или список?**
*   **Ответ:** Вектор.
*   **Термин "Промахи кэша" (Cache Misses):** Процессор читает память не по 1 байту, а кусками (линиями). Читая вектор, он за один раз загружает сразу кучу элементов. Читая список, он загружает один узел, а следующий узел может быть в другом конце памяти — приходится грузить снова. Это дорого.

**3. Вставка $10^7$ элементов: Vector vs List?**
*   **Вектор:** Если сделать `reserve` (зарезервировать память), он выделит память 1 раз.
*   **Список:** Он будет вызывать оператор `new` (запрашивать память у системы) 10 миллионов раз. Это очень-очень медленно.

**4-8. Вставки и удаления в векторе.**
*   **Конец:** Быстро ($O(1)$). Просто занимаем следующую свободную ячейку.
*   **Начало/Середина:** Медленно ($O(n)$). Представь, что люди сидят на лавочке плотно. Чтобы посадить кого-то в середину, нужно попросить всех, кто справа, подвинуться. Компьютер реально копирует байты в соседние ячейки.

**9. Удаление произвольного элемента за $O(1)$ (трюк).**
*   Если нам плевать на порядок элементов:
    1.  Берем тот, который надо удалить.
    2.  Копируем в него значение из **последнего** элемента.
    3.  Удаляем последний элемент (это дешево, не надо сдвигать).
    *   В итоге "дырка" закрыта последним элементом.

**10. Задача про числа (Counting Sort).**
*   На входе $N$ чисел, но сами числа маленькие (1..1000).
*   Мы заводим массив `counts` размером 1001.
*   Идем по входным числам. Если видим число `5`, делаем `counts[5]++`.
*   Нам не нужно запоминать, в каком порядке шли числа. Нам нужно только *количество* каждого. Это экономит память (храним 1000 счетчиков вместо миллиардов чисел).

**11. Зачем `reserve()` у вектора?**
*   **Термины:**
    *   `size`: сколько элементов реально лежит.
    *   `capacity` (емкость): под сколько элементов выделена память «про запас».
*   Когда `size` догоняет `capacity`, вектор ищет новый кусок памяти (в 2 раза больше), копирует все туда и удаляет старое. Это тяжелая операция (**Реаллокация**).
*   `reserve(100)` сразу делает `capacity = 100`. Реаллокаций не будет, пока мы не превысим 100. Это ускорение.
